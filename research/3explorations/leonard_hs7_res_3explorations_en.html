<div>
    <div class="background-box">
        <div class="container">
            <div class="col">
                <h3>The Seventh Volume of Brandes' <em>Main Currents</em></h3>
                <p>contributor: <span class="author">Peter Leonard</span></p>
                <p>This newly-discovered (?) seventh volume of <em>Hovedstr√∏mninger i det 19de
                        Aarhundredes Litteratur</em> emerged from the fevered workings of a
                    "recurrent neural network".</p>
            </div>
        </div>
    </div>
    <div class="container">
        <aside class="col-md-4">
            <h4>Contributor</h4>
            <p>Peter Leonard, Digital Humanities Lab, Yale University Libraries</p>
            <h4>Title</h4>
            <p>The Seventh Volume of Brandes' <em>Main Currents</em></p>
            <h4>Link</h4>
            <p>http://dh.library.yale.edu/projects/brandes/</p>
            <h4>Last edited</h4>
            <p>11-06-19</p>
        </aside>

        <div class="col-md-8">
            <p>The fake Brandes can be accessed <a
                    href="https://http://dh.library.yale.edu/projects/brandes/" target="_blank">
                    here</a>. The book is the result of a "recurrent neural network" <a
                    href="https://en.wikipedia.org/wiki/Recurrent_neural_network/" target="_blank">
                    (Wikipedia)</a> trained on the six extant volumes of this work. This kind of
                artificial intelligence system makes a comprehensive series of observations about
                real texts and uses what it learns to predict hypothetical future works. Unlike
                earlier approaches of text generation such as markov chains <a
                    href="https://en.wikipedia.org/wiki/Markov_chain/" target="_blank">
                    (Wikipedia)</a>, this character-level RNN works on a letter-by-letter basis.</p>
            <p>As such it may be interesting to observe the network has learned the capitalization
                rules of nouns in 19th century Danish, despite starting from a purely random state
                in which no letter is more or less likely to follow another.</p>
            <p>Try refreshing the page if you (do not) like what you read.</p>

            <p>Software:</p>
            <ul style="list-style-type:none;"><li>textgenrnn by Mac Woolf: <a href="https://github.com/minimaxir/textgenrnn/"
                    target="_blank"> https://github.com/minimaxir/textgenrnn/</a></li>
            </ul>

            <p>Further reading:</p>
            <ul style="list-style-type:none;">
                <li><a href="https://minimaxir.com/2018/05/text-neural-networks/" target="_blank">
                    https://minimaxir.com/2018/05/text-neural-networks/</a></li>
           
                <li><a href="https://github.com/karpathy/char-rnn/" target="_blank">
                    https://github.com/karpathy/char-rnn</a></li>
            </ul>
        </div>
    </div>
</div>
